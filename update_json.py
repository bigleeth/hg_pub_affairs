import requests
from bs4 import BeautifulSoup
import json
import pandas as pd
from datetime import datetime
from zoneinfo import ZoneInfo

### =============== êµ­íšŒì˜ì› ì •ë³´ ìˆ˜ì§‘ ===============
cookies_members = {
    '_fwb': '224GIbJbv3W2VKbiHHpHIKa.1736910833680',
    '_ga': 'GA1.1.1553764147.1736910835',
    'PCID': '756e904c-0b66-a4a7-6836-589756f10a6e-1736910838628',
    'JSESSIONID': 'your_valid_session',
    'PHAROSVISITOR': '00006eb50196285f2f296cc80ac965a6',
}
headers_members = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9',
    'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
    'Connection': 'keep-alive'
}
members = [
    ("ê¹€ì˜ì§„", "KIMYOUNGJIN"),
    ("ì •íƒœí˜¸", "JUNGTAEHO"),
    ("ê¹€ì˜í™˜", "KIMYOUNGWHAN"),
    ("ê¹€íƒœë…„", "KIMTAENYEON"),
    ("ë°•í™ê·¼", "PARKHONGKEUN"),
    ("ë°•ë¯¼ê·œ", "PARKMINKYU"),
    ("ì•ˆê·œë°±", "AHNGYUBACK"),
    ("ì•ˆë„ê±¸", "AHNDOGEOL"),
    ("ì˜¤ê¸°í˜•", "OHGIHYOUNG"),
    ("ì´ì†Œì˜", "LEESOYOUNG"),
    ("ì •ì„±í˜¸", "JUNGSUNGHO"),
    ("ì •ì¼ì˜", "CHUNGILYOUNG"),
    ("ì¡°ìŠ¹ë˜", "JOSEOUNGLAE"),
    ("ì§„ì„±ì¤€", "JINSUNGJOON"),
    ("ì†¡ì–¸ì„", "SONGEONSEOG"),
    ("ë°•ìˆ˜ì˜", "PARKSOOYOUNG"),
    ("ë°•ëŒ€ì¶œ", "PARKDAECHUL"),
    ("ë°•ì„±í›ˆ", "PARKSUNGHOON"),
    ("ìœ ìƒë²”", "YOOSANGBUM"),
    ("ìœ¤ì˜ì„", "YOONYOUNGSEOK"),
    ("ì´ì¸ì„ ", "LEEINSEON"),
    ("ì„ì´ì", "LIMLEEJA"),
    ("ìµœì€ì„", "CHOIEUNSEOK"),
    ("ì°¨ê·œê·¼", "CHAGYUGEUN"),
    ("ì²œí•˜ëŒ", "CHUNHARAM"),
    ("ìµœê¸°ìƒ", "CHOIKISANG"),
    ("ê¶Œì˜ì„¸", "KWONYOUNGSE"),

]

# ì •ë‹¹ ì •ë³´ ë§¤í•‘
party_mapping = {
    "ì •íƒœí˜¸": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
    "ê¹€ì˜ì§„": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
    "ê¹€ì˜í™˜": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
    "ê¹€íƒœë…„": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
    "ë°•í™ê·¼": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
    "ë°•ë¯¼ê·œ": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
    "ì•ˆê·œë°±": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
    "ì•ˆë„ê±¸": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
    "ì˜¤ê¸°í˜•": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
    "ì´ì†Œì˜": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
    "ì •ì„±í˜¸": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
    "ì •ì¼ì˜": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
    "ì¡°ìŠ¹ë˜": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
    "ì§„ì„±ì¤€": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
    "ìµœê¸°ìƒ": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
    "ì†¡ì–¸ì„": "êµ­ë¯¼ì˜í˜",
    "ë°•ìˆ˜ì˜": "êµ­ë¯¼ì˜í˜",
    "ë°•ëŒ€ì¶œ": "êµ­ë¯¼ì˜í˜",
    "ë°•ì„±í›ˆ": "êµ­ë¯¼ì˜í˜",
    "ìœ ìƒë²”": "êµ­ë¯¼ì˜í˜",
    "ìœ¤ì˜ì„": "êµ­ë¯¼ì˜í˜",
    "ì´ì¸ì„ ": "êµ­ë¯¼ì˜í˜",
    "ì„ì´ì": "êµ­ë¯¼ì˜í˜",
    "ìµœì€ì„": "êµ­ë¯¼ì˜í˜",
    "ê¶Œì˜ì„¸": "êµ­ë¯¼ì˜í˜",
    "ì°¨ê·œê·¼": "ì¡°êµ­í˜ì‹ ë‹¹",
    "ì²œí•˜ëŒ": "ê°œí˜ì‹ ë‹¹"
}




def extract_member_data(soup, name, member_id, response):
    try:
        name_el = soup.find('span', class_='sr-only')
        name = name_el.text.strip() if name_el else name
        party = party_mapping.get(name, "ì •ë³´ ì—†ìŒ")
        election_count, district, committee = "ì •ë³´ ì—†ìŒ", "ì •ë³´ ì—†ìŒ", "ì •ë³´ ì—†ìŒ"
        for dt in soup.find_all('dt'):
            if dt.text == 'ë‹¹ì„ íšŸìˆ˜':
                election_count = dt.find_next('dd').text.strip()[:2]
            elif dt.text == 'ì„ ê±°êµ¬':
                district = dt.find_next('dd').text.strip()
            elif dt.text == 'ì†Œì†ìœ„ì›íšŒ':
                committee = dt.find_next('dd').text.strip()
        chief, senior, secretary = [], [], []
        for li in soup.find_all('li'):
            title = li.find('dt')
            value = li.find('dd')
            if not title or not value:
                continue
            role = title.text.strip()
            names = [n.strip() for n in value.text.split(',')]
            if 'ë³´ì¢Œê´€' in role:
                chief = names
            elif 'ì„ ì„ë¹„ì„œê´€' in role:
                senior = names
            elif 'ë¹„ì„œê´€' in role:
                secretary = names
        return {
            "êµ­íšŒì˜ì›": {
                "ì´ë¦„": name,
                "ì •ë‹¹": party,
                "ë‹¹ì„ íšŸìˆ˜": election_count,
                "ì„ ê±°êµ¬": district,
                "ì†Œì†ìœ„ì›íšŒ": committee
            },
            "ë³´ì¢Œê´€": chief,
            "ì„ ì„ë¹„ì„œê´€": senior,
            "ë¹„ì„œê´€": secretary,
            "ë©”íƒ€ë°ì´í„°": {
                "url": f"https://www.assembly.go.kr/members/22nd/{member_id}",
                "status_code": response.status_code,
                "ìˆ˜ì§‘ì¼ì‹œ": datetime.now(ZoneInfo("Asia/Seoul")).strftime("%Y-%m-%d %H:%M:%S")
            }
        }
    except Exception as e:
        return {
            "êµ­íšŒì˜ì›": {
                "ì´ë¦„": name,
                "ì •ë‹¹": party_mapping.get(name, "ì •ë³´ ì—†ìŒ"),
                "ë‹¹ì„ íšŸìˆ˜": "ì •ë³´ ì—†ìŒ",
                "ì„ ê±°êµ¬": "ì •ë³´ ì—†ìŒ",
                "ì†Œì†ìœ„ì›íšŒ": "ì •ë³´ ì—†ìŒ"
            },
            "ë³´ì¢Œê´€": [], "ì„ ì„ë¹„ì„œê´€": [], "ë¹„ì„œê´€": [],
            "ë©”íƒ€ë°ì´í„°": {
                "url": f"https://www.assembly.go.kr/members/22nd/{member_id}",
                "status_code": 500,
                "ìˆ˜ì§‘ì¼ì‹œ": datetime.now(ZoneInfo("Asia/Seoul")).strftime("%Y-%m-%d %H:%M:%S")
            }
        }

all_member_data = []
for name, member_id in members:
    try:
        url = f'https://www.assembly.go.kr/members/22nd/{member_id}'
        response = requests.get(url, cookies=cookies_members, headers=headers_members)
        soup = BeautifulSoup(response.text, 'html.parser')
        data = extract_member_data(soup, name, member_id, response)
        all_member_data.append(data)
    except Exception as e:
        print(f"[ERROR] {name} failed: {e}")

with open('assembly_member_data.json', 'w', encoding='utf-8') as f:
    json.dump(all_member_data, f, ensure_ascii=False, indent=4)
print("âœ… êµ­íšŒì˜ì› ì •ë³´ ì €ì¥ ì™„ë£Œ")

import requests
import json
import pandas as pd
from datetime import datetime
from zoneinfo import ZoneInfo


# ==============================================================================
# ì˜ì•ˆ ì •ë³´ ìˆ˜ì§‘ (API ë°©ì‹ ì ìš©)
# ==============================================================================

def collect_bill_info_api(bill_name: str):
    """
    findSchPaging.do APIë¥¼ ì‚¬ìš©í•˜ì—¬ JSON ë°ì´í„°ë¥¼ ì§ì ‘ ë°›ì•„ì˜µë‹ˆë‹¤.
    """
    url = 'https://likms.assembly.go.kr/bill/bi/bill/sch/findSchPaging.do'
    
    # ì„¸ì…˜ ìƒì„± (ì¿ í‚¤ ë° í—¤ë” ê´€ë¦¬)
    session = requests.Session()
    
    # 1. ê¸°ë³¸ í—¤ë” ì„¤ì •
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Referer': 'https://likms.assembly.go.kr/bill/bi/bill/sch/detailedSchPage.do',
        'Content-Type': 'application/x-www-form-urlencoded;charset=UTF-8',
        'X-Requested-With': 'XMLHttpRequest'  # AJAX ìš”ì²­ì„ì„ ëª…ì‹œ
    })

    # 2. ìš”ì²­ ë°ì´í„° (Payload) ì„¤ì •
    # billNmì— ê²€ìƒ‰ì–´ë¥¼ ë„£ê³ , ageFrom/ageToì— '22'(22ëŒ€ êµ­íšŒ)ë¥¼ ì„¤ì •
    data = {
        'reqPageId': 'billSrch',
        'detailedTab': 'billDtl',
        'billNm': bill_name,     # ê²€ìƒ‰ì–´ ì£¼ì…
        'ageFrom': '22',         # 22ëŒ€ êµ­íšŒ ì‹œì‘
        'ageTo': '22',           # 22ëŒ€ êµ­íšŒ ë
        'ageCmtId': 'ì „ì²´',
        'billKind': 'ì „ì²´',
        'proposerKind': 'ì „ì²´',
        'procGbnCd': 'ì „ì²´',
        'page': '1',
        'rows': '50',            # í•œ ë²ˆì— ê°€ì ¸ì˜¬ ê°œìˆ˜ (ë„‰ë„‰í•˜ê²Œ ì„¤ì •)
        'schSorting': 'score',
        'ordCd': 'DESC'
    }

    try:
        # POST ìš”ì²­ ì „ì†¡
        response = session.post(url, data=data, timeout=30)
        response.raise_for_status()
        
        # ì‘ë‹µì´ JSONì¸ì§€ í™•ì¸
        try:
            result_json = response.json()
        except json.JSONDecodeError:
            print(f"âš ï¸ [{bill_name}] ì‘ë‹µì´ JSONì´ ì•„ë‹™ë‹ˆë‹¤. (HTML ë°˜í™˜ë¨)")
            return []

        # JSON êµ¬ì¡° íŒŒì•… (ë³´í†µ 'cl1_billSearchResult' ë˜ëŠ” 'resList' í‚¤ì— ë¦¬ìŠ¤íŠ¸ê°€ ìˆìŒ)
        # ì‹¤ì œ ì‘ë‹µ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ë©° ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
        bill_list = []
        if 'cl1_billSearchResult' in result_json:
            bill_list = result_json['cl1_billSearchResult']
        elif 'resList' in result_json:
            bill_list = result_json['resList']
        
        print(f"ğŸ” [{bill_name}] ê²€ìƒ‰ ì„±ê³µ: {len(bill_list)}ê±´ ë°œê²¬")

        parsed_bills = []
        for item in bill_list:
            # API í•„ë“œëª… ë§¤í•‘ (ëŒ€ì†Œë¬¸ì ì£¼ì˜)
            # ë³´í†µ API ë°˜í™˜ê°’ì€: BILL_ID, BILL_NAME, PROPOSER, PROPOSE_DT, PROC_RESULT_CD ë“±
            
            bill_id = item.get('BILL_ID') or item.get('billId')
            bill_no = item.get('BILL_NO') or item.get('billNo')
            full_title = item.get('BILL_NAME') or item.get('billName')
            proposer = item.get('PROPOSER') or item.get('proposer')
            propose_date = item.get('PROPOSE_DT') or item.get('proposeDt')
            status = item.get('PROC_RESULT_CD') or item.get('procResultCd') or "ì ‘ìˆ˜"

            # ì œëª© í•„í„°ë§ (ê²€ìƒ‰ì–´ í¬í•¨ ì—¬ë¶€ í™•ì¸)
            if bill_name.replace(" ", "") not in full_title.replace(" ", ""):
                continue

            parsed_bills.append({
                "ì˜ì•ˆë²ˆí˜¸": bill_no,
                "ì˜ì•ˆID": bill_id,
                "ì˜ì•ˆëª…": {
                    "text": full_title,
                    "link": f"https://likms.assembly.go.kr/bill/bi/bill/detail.do?billId={bill_id}" if bill_id else ""
                },
                "ì œì•ˆì": proposer,
                "ì œì•ˆì¼ì": propose_date,
                "ì‹¬ì‚¬ì§„í–‰ìƒíƒœ": status,
                "ìˆ˜ì§‘ì¼ì‹œ": datetime.now(ZoneInfo("Asia/Seoul")).strftime("%Y-%m-%d %H:%M:%S")
            })
            print(f"   âœ… ìˆ˜ì§‘: {full_title}")

        return parsed_bills

    except Exception as e:
        print(f"âš ï¸ [{bill_name}] API ìš”ì²­ ì‹¤íŒ¨: {e}")
        return []

# ==============================================================================
# ì‹¤í–‰ ë¡œì§
# ==============================================================================

# ìˆ˜ì§‘í•  ë²•ì•ˆ ëª©ë¡
bill_names = [
    "í•œêµ­ìˆ˜ì¶œì…ì€í–‰ë²• ì¼ë¶€ê°œì •ë²•ë¥ ì•ˆ",
    "ê²½ì œì•ˆë³´ë¥¼ ìœ„í•œ ê³µê¸‰ë§ ì•ˆì •í™” ì§€ì› ê¸°ë³¸ë²• ì¼ë¶€ê°œì •ë²•ë¥ ì•ˆ",
    "ì²¨ë‹¨ì¡°ì„ ì—…ì˜ ê²½ìŸë ¥ ê°•í™” ë° ì§€ì›ì— ê´€í•œ íŠ¹ë³„ë²•ì•ˆ",
    "ê³µê³µê¸°ê´€ì˜ ìš´ì˜ì— ê´€í•œ ë²•ë¥  ì¼ë¶€ê°œì •ë²•ë¥ ì•ˆ",
    "í•œêµ­ì‚°ì—…ì€í–‰ë²• ì¼ë¶€ê°œì •ë²•ë¥ ì•ˆ",
    "2025ë…„ë„ì— ë°œí–‰í•˜ëŠ” ì²¨ë‹¨ì „ëµì‚°ì—…ê¸°ê¸ˆì±„ê¶Œì— ëŒ€í•œ êµ­ê°€ë³´ì¦ë™ì˜ì•ˆ",
    "ì¤‘ì†Œê¸°ì—…ì€í–‰ë²• ì¼ë¶€ê°œì •ë²•ë¥ ì•ˆ",
    "ì •ë¶€ì¡°ì§ë²• ì¼ë¶€ê°œì •ë²•ë¥ ì•ˆ",
    "ì‹ ìš©ë³´ì¦ê¸°ê¸ˆë²• ì¼ë¶€ê°œì •ë²•ë¥ ì•ˆ",
    "ë™ë‚¨ê¶Œì‚°ì—…íˆ¬ìê³µì‚¬ ì„¤ë¦½ ë° ìš´ì˜ì— ê´€í•œ ë²•ë¥ ì•ˆ",
    "ì¶©ì²­ê¶Œì‚°ì—…íˆ¬ìê³µì‚¬ ì„¤ë¦½ ë° ìš´ì˜ì— ê´€í•œ ë²•ë¥ ì•ˆ",
    "ê¸°í›„ìœ„ê¸° ëŒ€ì‘ì„ ìœ„í•œ íƒ„ì†Œì¤‘ë¦½ã†ë…¹ìƒ‰ì„±ì¥ ê¸°ë³¸ë²• ì¼ë¶€ê°œì •ë²•ë¥ ì•ˆ"
]

all_bills = []
print("ğŸš€ API ê¸°ë°˜ ì˜ì•ˆ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘...")

for name in bill_names:
    bills = collect_bill_info_api(name)
    all_bills.extend(bills)

# ê²°ê³¼ ì €ì¥
with open("ì˜ì•ˆì •ë³´ê²€ìƒ‰ê²°ê³¼.json", "w", encoding="utf-8") as f:
    json.dump(all_bills, f, ensure_ascii=False, indent=4)

print(f"âœ… ì˜ì•ˆ ì •ë³´ ì €ì¥ ì™„ë£Œ: ì´ {len(all_bills)}ê±´")

# (ì†Œìœ„ì›íšŒ ì •ë³´ ìˆ˜ì§‘ ì½”ë“œë„ í•„ìš”í•˜ë‹¤ë©´ ì•„ë˜ì— ìœ ì§€)


### =============== ì†Œìœ„ì›íšŒ ì •ë³´ ìˆ˜ì§‘ ===============
# ì„¸ì…˜ ê°ì²´ ìƒì„±
session = requests.Session()

# ë©”ì¸ í˜ì´ì§€ URL
main_url = 'https://finance.na.go.kr:444/cmmit/mem/cmmitMemList/subCmt.do?menuNo=2000014'

# í—¤ë” ì •ì˜
headers = {
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'ko-KR,ko;q=0.9',
    'Cache-Control': 'no-cache',
    'Connection': 'keep-alive',
    'Pragma': 'no-cache',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',
}

try:
    # ë©”ì¸ í˜ì´ì§€ ìš”ì²­
    main_response = session.get(main_url, headers=headers)
    main_response.raise_for_status()

    # CSRF ë©”íƒ€ íƒœê·¸ ì¶”ì¶œ
    soup = BeautifulSoup(main_response.text, 'html.parser')
    csrf_parameter = soup.find('meta', {'name': '_csrf_parameter'})
    csrf_header = soup.find('meta', {'name': '_csrf_header'})
    csrf_token = soup.find('meta', {'name': '_csrf'})

    if not all([csrf_parameter, csrf_header, csrf_token]):
        raise ValueError("CSRF ë©”íƒ€ íƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    csrf_parameter_value = csrf_parameter['content']
    csrf_header_value = csrf_header['content']
    csrf_token_value = csrf_token['content']

    # POST ìš”ì²­ í—¤ë” ì„¤ì •
    api_headers = {
        'Accept': 'application/json, text/javascript, */*; q=0.01',
        'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
        'Origin': 'https://finance.na.go.kr:444',
        'Referer': main_url,
        'User-Agent': headers['User-Agent'],
        'X-Requested-With': 'XMLHttpRequest',
        csrf_header_value: csrf_token_value
    }

    data = {
        'hgNm': '',
        'subCmtNm': '',
        'pageUnit': '9',
        'pageIndex': '',
        csrf_parameter_value: csrf_token_value
    }

    response = session.post(
        'https://finance.na.go.kr:444/cmmit/mem/cmmitMemList/getSubCmitLst.json',
        headers=api_headers,
        data=data
    )
    response.raise_for_status()
    response_data = response.json()

except requests.exceptions.RequestException as e:
    print(f"ìš”ì²­ ì‹¤íŒ¨: {e}")
    exit(1)
except json.JSONDecodeError as e:
    print(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
    print("ì‘ë‹µ ì›ë¬¸:", response.text)
    exit(1)
except Exception as e:
    print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
    exit(1)

# â—ˆì´ë¦„ â†’ ì´ë¦„(é•·)ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def parse_members(member_str):
    members = []
    for m in member_str.split(','):
        m = m.strip()
        if m.startswith('â—ˆ'):
            m = m.lstrip('â—ˆ')  # remove diamond
            if '(é•·)' not in m:
                name_part, sep, han_part = m.partition('(')
                m = f"(é•·){name_part}{sep}{han_part}"  # insert "(é•·)" before names
        members.append(m)
    return members

# ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ êµ¬ì„±
result = {}

for item in response_data.get("resultList", []):
    committee_name = item["sbcmtNm"]
    count = item["naasCnt"]
    key = f"{committee_name}({count}ì¸)"
    
    parties = {}
    if item.get("poly1NaasNm") and item.get("poly1NaasCn"):
        parties[item["poly1NaasNm"]] = parse_members(item["poly1NaasCn"])
    if item.get("poly2NaasNm") and item.get("poly2NaasCn"):
        parties[item["poly2NaasNm"]] = parse_members(item["poly2NaasCn"])
    if item.get("poly99NaasNm") and item.get("poly99NaasCn"):
        parties[item["poly99NaasNm"]] = parse_members(item["poly99NaasCn"])
    
    result[key] = parties

# ë©”íƒ€ë°ì´í„° êµ¬ì„±
metadata = {
    "ìˆ˜ì§‘ì¼ì‹œ": datetime.now(ZoneInfo("Asia/Seoul")).strftime("%Y-%m-%d %H:%M:%S"),
    "url": main_url,
    "status_code": response.status_code
}

# ìµœì¢… ê²°ê³¼ ì €ì¥
final_result = {
    "ì†Œìœ„ì›íšŒ_ì •ë³´": result,
    "ë©”íƒ€ë°ì´í„°": metadata
}

with open('ì†Œìœ„ì›íšŒì •ë³´.json', 'w', encoding='utf-8') as f:
    json.dump(final_result, f, ensure_ascii=False, indent=4)
print("âœ… ì†Œìœ„ì›íšŒ ì •ë³´ ì €ì¥ ì™„ë£Œ")














